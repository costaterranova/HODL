{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "secret='iFYDcYUNWwgFPAEwk6_vmA3ZQ2WIbQ'\n",
    "client_id='uCLonTkFBuYPaFa_1cRZ3Q'\n",
    "user_agent='Love Letters From Macao'\n",
    "username='Existing_Dog5489'\n",
    "password='kabar bahy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Version 7.6.1 of praw is outdated. Version 7.7.0 was released Saturday February 25, 2023.\n"
     ]
    }
   ],
   "source": [
    "# Read-only instance\n",
    "reddit_read_only = praw.Reddit(client_id=client_id,         # your client id\n",
    "                               client_secret=secret,      # your client secret\n",
    "                               user_agent=user_agent)        # your user agent\n",
    " \n",
    "# Authorized instance\n",
    "reddit_authorized = praw.Reddit(client_id=client_id,         # your client id\n",
    "                               client_secret=secret,      # your client secret\n",
    "                               user_agent=user_agent,        # your user agent\n",
    "                                username=username,        # your reddit username\n",
    "                                password=password)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What Are Your Moves Tomorrow, March 14, 2023\n",
      "\n",
      "Most Anticipated Earnings Releases for the week beginning March 13th, 2023\n",
      "\n",
      "Live from The US Treasury\n",
      "\n",
      "I canâ€™t wait until March 22.\n",
      "\n",
      "First Republic down 60% premarket\n",
      "\n"
     ]
    }
   ],
   "source": [
    "subreddit = reddit_read_only.subreddit(\"wallstreetbets\")\n",
    " \n",
    "for post in subreddit.hot(limit=5):\n",
    "    print(post.title)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-f2aa57c2384a>:1: DeprecationWarning: Positional arguments for 'BaseListingMixin.top' will no longer be supported in PRAW 8.\n",
      "Call this function with 'time_filter' as a keyword argument.\n",
      "  posts = subreddit.top(\"month\")\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-f2aa57c2384a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m               }\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mpost\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mposts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;31m# Title of each post\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mposts_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Title\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpost\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/praw/models/listing/generator.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_listing\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_list_index\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_listing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_list_index\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/praw/models/listing/generator.py\u001b[0m in \u001b[0;36m_next_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_listing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reddit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_listing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extract_sublist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_listing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_list_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/praw/util/deprecate_args.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     41\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                 )\n\u001b[0;32m---> 43\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_old_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/praw/reddit.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, path, params)\u001b[0m\n\u001b[1;32m    710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m         \"\"\"\n\u001b[0;32m--> 712\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_objectify_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"GET\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    713\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0m_deprecate_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"fullnames\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"url\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"subreddits\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/praw/reddit.py\u001b[0m in \u001b[0;36m_objectify_request\u001b[0;34m(self, data, files, json, method, params, path)\u001b[0m\n\u001b[1;32m    515\u001b[0m         \"\"\"\n\u001b[1;32m    516\u001b[0m         return self._objector.objectify(\n\u001b[0;32m--> 517\u001b[0;31m             self.request(\n\u001b[0m\u001b[1;32m    518\u001b[0m                 \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m                 \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/praw/util/deprecate_args.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     41\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                 )\n\u001b[0;32m---> 43\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_old_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/praw/reddit.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, data, files, json, method, params, path)\u001b[0m\n\u001b[1;32m    939\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mClientException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"At most one of 'data' or 'json' is supported.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    940\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 941\u001b[0;31m             return self._core.request(\n\u001b[0m\u001b[1;32m    942\u001b[0m                 \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    943\u001b[0m                 \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/prawcore/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, path, data, files, json, params, timeout)\u001b[0m\n\u001b[1;32m    328\u001b[0m             \u001b[0mjson\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"api_type\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"json\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murljoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_requestor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moauth_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m         return self._request_with_retries(\n\u001b[0m\u001b[1;32m    331\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m             \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/prawcore/sessions.py\u001b[0m in \u001b[0;36m_request_with_retries\u001b[0;34m(self, data, files, json, method, params, timeout, url, retry_strategy_state)\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0mretry_strategy_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m         response, saved_exception = self._make_request(\n\u001b[0m\u001b[1;32m    229\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0mfiles\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/prawcore/sessions.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, data, files, json, method, params, retry_strategy_state, timeout, url)\u001b[0m\n\u001b[1;32m    183\u001b[0m     ):\n\u001b[1;32m    184\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m             response = self._rate_limiter.call(\n\u001b[0m\u001b[1;32m    186\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_requestor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_header_callback\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/prawcore/rate_limit.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, request_function, set_header_callback, *args, **kwargs)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \"\"\"\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"headers\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset_header_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/prawcore/rate_limit.py\u001b[0m in \u001b[0;36mdelay\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Sleeping: {sleep_seconds:0.2f} seconds prior to call\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msleep_seconds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse_headers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "posts = subreddit.top(\"month\")\n",
    "# Scraping the top posts of the current month\n",
    " \n",
    "posts_dict = {\"Title\": [], \"Post Text\": [],\n",
    "              \"ID\": [], \"Score\": [],\n",
    "              \"Total Comments\": [], \"Post URL\": []\n",
    "              }\n",
    " \n",
    "for post in posts:\n",
    "    # Title of each post\n",
    "    posts_dict[\"Title\"].append(post.title)\n",
    "     \n",
    "    # Text inside a post\n",
    "    posts_dict[\"Post Text\"].append(post.selftext)\n",
    "     \n",
    "    # Unique ID of each post\n",
    "    posts_dict[\"ID\"].append(post.id)\n",
    "     \n",
    "    # The score of a post\n",
    "    posts_dict[\"Score\"].append(post.score)\n",
    "     \n",
    "    # Total number of comments inside the post\n",
    "    posts_dict[\"Total Comments\"].append(post.num_comments)\n",
    "     \n",
    "    # URL of each post\n",
    "    posts_dict[\"Post URL\"].append(post.url)\n",
    " \n",
    "# Saving the data in a pandas dataframe\n",
    "top_posts = pd.DataFrame(posts_dict)\n",
    "top_posts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d58201645fac422aa77984d36fa4c621",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "########################################\n",
    "#   CREATING DICTIONARY TO STORE THE DATA WHICH WILL BE CONVERTED TO A DATAFRAME\n",
    "########################################\n",
    "\n",
    "#   NOTE: ALL THE POST DATA AND COMMENT DATA WILL BE SAVED IN TWO DIFFERENT\n",
    "#   DATASETS AND LATER CAN BE MAPPED USING IDS OF POSTS/COMMENTS AS WE WILL \n",
    "#   BE CAPTURING ALL IDS THAT COME IN OUR WAY\n",
    "\n",
    "# SCRAPING CAN BE DONE VIA VARIOUS STRATEGIES {HOT,TOP,etc} we will go with keyword strategy i.e using search a keyword\n",
    "\n",
    "query = ['what stock should I buy'] ## put here main stocks\n",
    "\n",
    "for item in query:\n",
    "    post_dict = {\n",
    "        \"title\" : [],   #title of the post\n",
    "       # \"score\" : [],   # score of the post\n",
    "       # \"id\" : [],      # unique id of the post\n",
    "       # \"url\" : [],     #url of the post\n",
    "       # \"comms_num\": [],   #the number of comments on the post\n",
    "       # \"created\" : [],  #timestamp of the post\n",
    "        \"body\" : []         # the descriptionof post\n",
    "    }\n",
    "    comments_dict = {\n",
    "       # \"comment_id\" : [],      #unique comm id\n",
    "       # \"comment_parent_id\" : [],   # comment parent id\n",
    "        \"comment_body\" : [],   # text in comment\n",
    "       # \"comment_link_id\" : []  #link to the comment\n",
    "    }\n",
    "    for submission in tqdm(subreddit.search(query,sort = \"top\", time_filter=\"week\", limit = 15)):\n",
    "        post_dict[\"title\"].append(submission.title)\n",
    "       # post_dict[\"score\"].append(submission.score)\n",
    "       # post_dict[\"id\"].append(submission.id)\n",
    "       # post_dict[\"url\"].append(submission.url)\n",
    "       # post_dict[\"comms_num\"].append(submission.num_comments)\n",
    "       # post_dict[\"created\"].append(submission.created)\n",
    "        post_dict[\"body\"].append(submission.selftext)\n",
    "        \n",
    "        ##### Acessing comments on the post\n",
    "        submission.comments.replace_more(limit = 10)\n",
    "        for comment in submission.comments.list():\n",
    "#            comments_dict[\"comment_id\"].append(comment.id)\n",
    "#            comments_dict[\"comment_parent_id\"].append(comment.parent_id)\n",
    "            comments_dict[\"comment_body\"].append(comment.body)\n",
    "#            comments_dict[\"comment_link_id\"].append(comment.link_id)\n",
    "    \n",
    "    post_comments = pd.DataFrame(comments_dict)\n",
    "\n",
    "#    post_comments.to_csv('wallstreetbets'+\"_comments_\"+ item +\"subreddit.csv\")\n",
    "#    post_data = pd.DataFrame(post_dict)\n",
    "#    post_data.to_csv('wallstreetbets'+\"_\"+ item +\"subreddit.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PRELIMINARY MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stocks = pd.read_csv('list_of_stocks.csv')\n",
    "all_stocks = all_stocks[all_stocks['Country'] == 'United States'].reset_index(drop=True)\n",
    "all_stocks = all_stocks[['Symbol', 'Name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "BLACKLIST = ['ev', 'covid', 'etf', 'nyse', 'sec', 'spac', 'fda', 'treasury', 'eod', 'fed', 'wsb', ]\n",
    "\n",
    "def get_orgs(text):\n",
    "    doc = nlp(text)\n",
    "    org_list = []\n",
    "    for entity in doc.ents:\n",
    "        # here we modify the original code to check that entity text is not equal to one of our 'blacklisted' organizations\n",
    "        # (we also add .lower() to lowercase the text, this allows us to match both 'nyse' and 'NYSE' with just 'nyse')\n",
    "        if entity.label_ == 'ORG' and entity.text.lower() not in BLACKLIST:\n",
    "            org_list.append(entity.text.lower())\n",
    "    # if organization is identified more than once it will appear multiple times in list\n",
    "    # we use set() to remove duplicates then convert back to list\n",
    "    org_list = list(set(org_list))\n",
    "    return org_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "post_comments['organizations'] = post_comments['comment_body'].apply(get_orgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    " # load the English language model\n",
    "\n",
    "# merge organizations column into one big list\n",
    "orgs = post_comments['organizations'].to_list()\n",
    "orgs = [org for sublist in orgs for org in sublist]\n",
    "\n",
    "from collections import Counter\n",
    "# create dictionary of organization mention frequency\n",
    "org_freq = Counter(orgs)\n",
    "most_common = org_freq.most_common(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in most_common:\n",
    "    if len(all_stocks[all_stocks['Symbol'] == item[0].upper()]) == 0:\n",
    "        continue\n",
    "    else:\n",
    "        final_ticker = item[0].upper()\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'IBKR'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_ticker"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What to sell?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.4.2\n"
     ]
    }
   ],
   "source": [
    "print(spacy.__version__)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Yahoo Finance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "yfinance.Tickers object <MSFT>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nyse_tickers = yf.Tickers('MSFT') \n",
    "nyse_tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93.08000183105469"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yf.Ticker('goog').fast_info.day_high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def history(self, period=\"1mo\", interval=\"1d\",\n",
    "            start=None, end=None, prepost=False, actions=True,\n",
    "            auto_adjust=True, back_adjust=False,\n",
    "            proxy=None, rounding=False, tz=None, timeout=None, **kwargs):\n",
    "    \"\"\"\n",
    "    :Parameters:\n",
    "        period : str\n",
    "            Valid periods: 1d,5d,1mo,3mo,6mo,1y,2y,5y,10y,ytd,max\n",
    "            Either Use period parameter or use start and end\n",
    "        interval : str\n",
    "            Valid intervals: 1m,2m,5m,15m,30m,60m,90m,1h,1d,5d,1wk,1mo,3mo\n",
    "            Intraday data cannot extend last 60 days\n",
    "        start: str\n",
    "            Download start date string (YYYY-MM-DD) or _datetime.\n",
    "            Default is 1900-01-01\n",
    "        end: str\n",
    "            Download end date string (YYYY-MM-DD) or _datetime.\n",
    "            Default is now\n",
    "        prepost : bool\n",
    "            Include Pre and Post market data in results?\n",
    "            Default is False\n",
    "        auto_adjust: bool\n",
    "            Adjust all OHLC automatically? Default is True\n",
    "        back_adjust: bool\n",
    "            Back-adjusted data to mimic true historical prices\n",
    "        proxy: str\n",
    "            Optional. Proxy server URL scheme. Default is None\n",
    "        rounding: bool\n",
    "            Round values to 2 decimal places?\n",
    "            Optional. Default is False = precision suggested by Yahoo!\n",
    "        tz: str\n",
    "            Optional timezone locale for dates.\n",
    "            (default data is returned as non-localized dates)\n",
    "        timeout: None or float\n",
    "            If not None stops waiting for a response after given number of\n",
    "            seconds. (Can also be a fraction of a second e.g. 0.01)\n",
    "            Default is None.\n",
    "        **kwargs: dict\n",
    "            debug: bool\n",
    "                Optional. If passed as False, will suppress\n",
    "                error message printing to console.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-02-14 00:00:00-05:00</th>\n",
       "      <td>94.660004</td>\n",
       "      <td>95.175003</td>\n",
       "      <td>92.650002</td>\n",
       "      <td>94.949997</td>\n",
       "      <td>42513100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-15 00:00:00-05:00</th>\n",
       "      <td>94.739998</td>\n",
       "      <td>97.339996</td>\n",
       "      <td>94.360001</td>\n",
       "      <td>97.099998</td>\n",
       "      <td>36964500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-16 00:00:00-05:00</th>\n",
       "      <td>95.540001</td>\n",
       "      <td>97.879997</td>\n",
       "      <td>94.970001</td>\n",
       "      <td>95.779999</td>\n",
       "      <td>35642100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-17 00:00:00-05:00</th>\n",
       "      <td>95.070000</td>\n",
       "      <td>95.750000</td>\n",
       "      <td>93.449997</td>\n",
       "      <td>94.589996</td>\n",
       "      <td>31095100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-21 00:00:00-05:00</th>\n",
       "      <td>93.239998</td>\n",
       "      <td>93.415001</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>92.050003</td>\n",
       "      <td>28367200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-22 00:00:00-05:00</th>\n",
       "      <td>91.933998</td>\n",
       "      <td>92.360001</td>\n",
       "      <td>90.870003</td>\n",
       "      <td>91.800003</td>\n",
       "      <td>29891100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-23 00:00:00-05:00</th>\n",
       "      <td>92.129997</td>\n",
       "      <td>92.129997</td>\n",
       "      <td>90.010002</td>\n",
       "      <td>91.070000</td>\n",
       "      <td>32423700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-24 00:00:00-05:00</th>\n",
       "      <td>89.629997</td>\n",
       "      <td>90.129997</td>\n",
       "      <td>88.860001</td>\n",
       "      <td>89.349998</td>\n",
       "      <td>31295600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-27 00:00:00-05:00</th>\n",
       "      <td>90.089996</td>\n",
       "      <td>90.449997</td>\n",
       "      <td>89.610001</td>\n",
       "      <td>90.099998</td>\n",
       "      <td>22724300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-28 00:00:00-05:00</th>\n",
       "      <td>89.540001</td>\n",
       "      <td>91.449997</td>\n",
       "      <td>89.519997</td>\n",
       "      <td>90.300003</td>\n",
       "      <td>30546900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-01 00:00:00-05:00</th>\n",
       "      <td>90.160004</td>\n",
       "      <td>91.199997</td>\n",
       "      <td>89.849998</td>\n",
       "      <td>90.510002</td>\n",
       "      <td>26323900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-02 00:00:00-05:00</th>\n",
       "      <td>89.860001</td>\n",
       "      <td>92.480003</td>\n",
       "      <td>89.769997</td>\n",
       "      <td>92.309998</td>\n",
       "      <td>23328600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-03 00:00:00-05:00</th>\n",
       "      <td>92.739998</td>\n",
       "      <td>94.110001</td>\n",
       "      <td>92.660004</td>\n",
       "      <td>94.019997</td>\n",
       "      <td>30220900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-06 00:00:00-05:00</th>\n",
       "      <td>94.360001</td>\n",
       "      <td>96.300003</td>\n",
       "      <td>94.300003</td>\n",
       "      <td>95.580002</td>\n",
       "      <td>28288200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-07 00:00:00-05:00</th>\n",
       "      <td>95.419998</td>\n",
       "      <td>96.089996</td>\n",
       "      <td>93.844002</td>\n",
       "      <td>94.169998</td>\n",
       "      <td>24101500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-08 00:00:00-05:00</th>\n",
       "      <td>94.404999</td>\n",
       "      <td>96.239998</td>\n",
       "      <td>94.404999</td>\n",
       "      <td>94.650002</td>\n",
       "      <td>25395200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-09 00:00:00-05:00</th>\n",
       "      <td>94.489998</td>\n",
       "      <td>95.919998</td>\n",
       "      <td>92.355003</td>\n",
       "      <td>92.660004</td>\n",
       "      <td>24438900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-10 00:00:00-05:00</th>\n",
       "      <td>92.500000</td>\n",
       "      <td>93.180000</td>\n",
       "      <td>90.800003</td>\n",
       "      <td>91.010002</td>\n",
       "      <td>32831700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-13 00:00:00-04:00</th>\n",
       "      <td>90.565002</td>\n",
       "      <td>93.080002</td>\n",
       "      <td>89.940002</td>\n",
       "      <td>91.660004</td>\n",
       "      <td>30514909</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Open       High        Low      Close  \\\n",
       "Date                                                                    \n",
       "2023-02-14 00:00:00-05:00  94.660004  95.175003  92.650002  94.949997   \n",
       "2023-02-15 00:00:00-05:00  94.739998  97.339996  94.360001  97.099998   \n",
       "2023-02-16 00:00:00-05:00  95.540001  97.879997  94.970001  95.779999   \n",
       "2023-02-17 00:00:00-05:00  95.070000  95.750000  93.449997  94.589996   \n",
       "2023-02-21 00:00:00-05:00  93.239998  93.415001  92.000000  92.050003   \n",
       "2023-02-22 00:00:00-05:00  91.933998  92.360001  90.870003  91.800003   \n",
       "2023-02-23 00:00:00-05:00  92.129997  92.129997  90.010002  91.070000   \n",
       "2023-02-24 00:00:00-05:00  89.629997  90.129997  88.860001  89.349998   \n",
       "2023-02-27 00:00:00-05:00  90.089996  90.449997  89.610001  90.099998   \n",
       "2023-02-28 00:00:00-05:00  89.540001  91.449997  89.519997  90.300003   \n",
       "2023-03-01 00:00:00-05:00  90.160004  91.199997  89.849998  90.510002   \n",
       "2023-03-02 00:00:00-05:00  89.860001  92.480003  89.769997  92.309998   \n",
       "2023-03-03 00:00:00-05:00  92.739998  94.110001  92.660004  94.019997   \n",
       "2023-03-06 00:00:00-05:00  94.360001  96.300003  94.300003  95.580002   \n",
       "2023-03-07 00:00:00-05:00  95.419998  96.089996  93.844002  94.169998   \n",
       "2023-03-08 00:00:00-05:00  94.404999  96.239998  94.404999  94.650002   \n",
       "2023-03-09 00:00:00-05:00  94.489998  95.919998  92.355003  92.660004   \n",
       "2023-03-10 00:00:00-05:00  92.500000  93.180000  90.800003  91.010002   \n",
       "2023-03-13 00:00:00-04:00  90.565002  93.080002  89.940002  91.660004   \n",
       "\n",
       "                             Volume  Dividends  Stock Splits  \n",
       "Date                                                          \n",
       "2023-02-14 00:00:00-05:00  42513100        0.0           0.0  \n",
       "2023-02-15 00:00:00-05:00  36964500        0.0           0.0  \n",
       "2023-02-16 00:00:00-05:00  35642100        0.0           0.0  \n",
       "2023-02-17 00:00:00-05:00  31095100        0.0           0.0  \n",
       "2023-02-21 00:00:00-05:00  28367200        0.0           0.0  \n",
       "2023-02-22 00:00:00-05:00  29891100        0.0           0.0  \n",
       "2023-02-23 00:00:00-05:00  32423700        0.0           0.0  \n",
       "2023-02-24 00:00:00-05:00  31295600        0.0           0.0  \n",
       "2023-02-27 00:00:00-05:00  22724300        0.0           0.0  \n",
       "2023-02-28 00:00:00-05:00  30546900        0.0           0.0  \n",
       "2023-03-01 00:00:00-05:00  26323900        0.0           0.0  \n",
       "2023-03-02 00:00:00-05:00  23328600        0.0           0.0  \n",
       "2023-03-03 00:00:00-05:00  30220900        0.0           0.0  \n",
       "2023-03-06 00:00:00-05:00  28288200        0.0           0.0  \n",
       "2023-03-07 00:00:00-05:00  24101500        0.0           0.0  \n",
       "2023-03-08 00:00:00-05:00  25395200        0.0           0.0  \n",
       "2023-03-09 00:00:00-05:00  24438900        0.0           0.0  \n",
       "2023-03-10 00:00:00-05:00  32831700        0.0           0.0  \n",
       "2023-03-13 00:00:00-04:00  30514909        0.0           0.0  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goog = yf.Ticker('goog')\n",
    "data = goog.history()\n",
    "data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_id</th>\n",
       "      <th>comment_parent_id</th>\n",
       "      <th>comment_body</th>\n",
       "      <th>comment_link_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jc0d8mt</td>\n",
       "      <td>t3_11pxw4j</td>\n",
       "      <td>\\n**User Report**| | | |\\n:--|:--|:--|:--\\n**T...</td>\n",
       "      <td>t3_11pxw4j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jc0f9tj</td>\n",
       "      <td>t3_11pxw4j</td>\n",
       "      <td>Holy shit SPY jumped up over 14% that day</td>\n",
       "      <td>t3_11pxw4j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>jc0kki3</td>\n",
       "      <td>t3_11pxw4j</td>\n",
       "      <td>Bullish until March 22nd because Jerome will r...</td>\n",
       "      <td>t3_11pxw4j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jc0de4m</td>\n",
       "      <td>t3_11pxw4j</td>\n",
       "      <td>So buy call puts?</td>\n",
       "      <td>t3_11pxw4j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jc13ac9</td>\n",
       "      <td>t3_11pxw4j</td>\n",
       "      <td>If they make this period into a movie I don't ...</td>\n",
       "      <td>t3_11pxw4j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>jc3u3q5</td>\n",
       "      <td>t1_jc31lpa</td>\n",
       "      <td>Unless you got a portfolio loan product they h...</td>\n",
       "      <td>t3_11qcafe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>jc31qjd</td>\n",
       "      <td>t1_jc31k5y</td>\n",
       "      <td>I'm in for 500 shares this morning. I'll see h...</td>\n",
       "      <td>t3_11qcafe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>jc3qq9d</td>\n",
       "      <td>t1_jc3q8ei</td>\n",
       "      <td>Homes may be damaged but fewer homes now exist...</td>\n",
       "      <td>t3_11qcafe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>jc36005</td>\n",
       "      <td>t1_jc347af</td>\n",
       "      <td>Yeah we only have enough cash in FR to keep th...</td>\n",
       "      <td>t3_11qcafe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>jc3bo1z</td>\n",
       "      <td>t1_jc36005</td>\n",
       "      <td>FR alleges that the reason for their slowness ...</td>\n",
       "      <td>t3_11qcafe</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>237 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    comment_id comment_parent_id  \\\n",
       "0      jc0d8mt        t3_11pxw4j   \n",
       "1      jc0f9tj        t3_11pxw4j   \n",
       "2      jc0kki3        t3_11pxw4j   \n",
       "3      jc0de4m        t3_11pxw4j   \n",
       "4      jc13ac9        t3_11pxw4j   \n",
       "..         ...               ...   \n",
       "232    jc3u3q5        t1_jc31lpa   \n",
       "233    jc31qjd        t1_jc31k5y   \n",
       "234    jc3qq9d        t1_jc3q8ei   \n",
       "235    jc36005        t1_jc347af   \n",
       "236    jc3bo1z        t1_jc36005   \n",
       "\n",
       "                                          comment_body comment_link_id  \n",
       "0    \\n**User Report**| | | |\\n:--|:--|:--|:--\\n**T...      t3_11pxw4j  \n",
       "1            Holy shit SPY jumped up over 14% that day      t3_11pxw4j  \n",
       "2    Bullish until March 22nd because Jerome will r...      t3_11pxw4j  \n",
       "3                                    So buy call puts?      t3_11pxw4j  \n",
       "4    If they make this period into a movie I don't ...      t3_11pxw4j  \n",
       "..                                                 ...             ...  \n",
       "232  Unless you got a portfolio loan product they h...      t3_11qcafe  \n",
       "233  I'm in for 500 shares this morning. I'll see h...      t3_11qcafe  \n",
       "234  Homes may be damaged but fewer homes now exist...      t3_11qcafe  \n",
       "235  Yeah we only have enough cash in FR to keep th...      t3_11qcafe  \n",
       "236  FR alleges that the reason for their slowness ...      t3_11qcafe  \n",
       "\n",
       "[237 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "import csv\n",
    "import urllib.request\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 499M/499M [00:21<00:00, 23.6MB/s] \n"
     ]
    }
   ],
   "source": [
    "# Preprocess text (username and link placeholders)\n",
    "def preprocess(text):\n",
    "    new_text = []\n",
    " \n",
    " \n",
    "    for t in text.split(\" \"):\n",
    "        t = '@user' if t.startswith('@') and len(t) > 1 else t\n",
    "        t = 'http' if t.startswith('http') else t\n",
    "        new_text.append(t)\n",
    "    return \" \".join(new_text)\n",
    "\n",
    "# Tasks:\n",
    "# emoji, emotion, hate, irony, offensive, sentiment\n",
    "# stance/abortion, stance/atheism, stance/climate, stance/feminist, stance/hillary\n",
    "\n",
    "task='sentiment'\n",
    "MODEL = f\"cardiffnlp/twitter-roberta-base-{task}\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "\n",
    "# download label mapping\n",
    "labels=[]\n",
    "mapping_link = f\"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/{task}/mapping.txt\"\n",
    "with urllib.request.urlopen(mapping_link) as f:\n",
    "    html = f.read().decode('utf-8').split(\"\\n\")\n",
    "    csvreader = csv.reader(html, delimiter='\\t')\n",
    "labels = [row[1] for row in csvreader if len(row) > 1]\n",
    "\n",
    "# PT\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "model.save_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) positive 0.8466\n",
      "2) neutral 0.1458\n",
      "3) negative 0.0076\n"
     ]
    }
   ],
   "source": [
    "\n",
    "text = \"Good night ðŸ˜Š\"\n",
    "text = preprocess(text)\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "output = model(**encoded_input)\n",
    "scores = output[0][0].detach().numpy()\n",
    "scores = softmax(scores)\n",
    "\n",
    "ranking = np.argsort(scores)\n",
    "ranking = ranking[::-1]\n",
    "for i in range(scores.shape[0]):\n",
    "    l = labels[ranking[i]]\n",
    "    s = scores[ranking[i]]\n",
    "    print(f\"{i+1}) {l} {np.round(float(s), 4)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "486fa0827316166d70c33d5310807918e94ee83115b30532896627e635d11957"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
